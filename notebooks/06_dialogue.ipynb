{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b0c2d3",
   "metadata": {},
   "source": "# LLM Part Dialogue — Bringing Parts to Life\n\nIn a real IFS session, the most powerful moment is when a client stops talking *about* a Part and starts talking *as* that Part. The Protector speaks in first person, reveals its fears, explains its strategies. The Exile whispers from the age when the wound was formed.\n\nV2 of `agentic-ifs` makes this computational. The **LLM Part Dialogue** system takes each Part's narrative, age, intent, and strategies, and constructs a system prompt that instructs an LLM to speak *as* that Part. The Part's voice is grounded in its IFS data — not generic chat.\n\nThis notebook demonstrates:\n1. Setting up the dialogue system with **Google Gemini** (via `GENAI_API_KEY`)\n2. Speaking *as* a Part through the Self system (`speak_as`)\n3. Direct Access mode — therapist speaks directly to a Part, bypassing Self\n4. Multi-turn conversation with memory\n5. The full therapeutic arc: dialogue during the 6 Fs and unburdening\n\n## Setup\n\n1. Copy `.env.example` to `.env.local` in the project root\n2. Add your Google API key: `GENAI_API_KEY=your-key-here`\n3. Run this notebook\n\n> **Disclaimer:** `agentic-ifs` is a research and simulation tool. It is **not clinical software** and is not intended for therapy delivery."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c3d4e5",
   "metadata": {},
   "outputs": [],
   "source": "from pathlib import Path\nfrom dotenv import load_dotenv\n\n# Load .env.local from project root\nload_dotenv(Path(\"../.env.local\"))\n\nimport os\nassert os.environ.get(\"GENAI_API_KEY\"), (\n    \"GENAI_API_KEY not found. Copy .env.example to .env.local and add your key.\"\n)\nprint(\"GENAI_API_KEY loaded.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d4e5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agentic_ifs import (\n",
    "    Session,\n",
    "    Manager,\n",
    "    Firefighter,\n",
    "    Exile,\n",
    "    Burden,\n",
    "    BurdenType,\n",
    "    Edge,\n",
    "    EdgeType,\n",
    "    build_part_system_prompt,\n",
    ")\n",
    "from agentic_ifs.integrations.google import GeminiDialogueProvider"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e5f6a7",
   "metadata": {},
   "source": [
    "## 1. Build the Internal System\n",
    "\n",
    "We create a realistic internal system: an **Inner Critic** (Manager) and a **Procrastinator** (Firefighter) both protecting a **Wounded Child** (Exile) who carries a burden of shame.\n",
    "\n",
    "The `GeminiDialogueProvider` reads `GENAI_API_KEY` from the environment automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f6a7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the LLM provider — reads GENAI_API_KEY from environment\n",
    "provider = GeminiDialogueProvider(model_name=\"gemini-2.5-flash\")\n",
    "\n",
    "# Create a Session with the dialogue provider\n",
    "session = Session(\n",
    "    initial_self_energy=0.8,\n",
    "    dialogue_provider=provider,\n",
    ")\n",
    "\n",
    "# Build Parts\n",
    "critic = Manager(\n",
    "    narrative=\"The Inner Critic — formed at age 12 after being humiliated in front of the class\",\n",
    "    age=12,\n",
    "    intent=\"Keep us safe from criticism by being perfect first\",\n",
    "    triggers=[\"criticism\", \"perceived failure\", \"being watched\"],\n",
    "    strategies=[\"perfectionism\", \"over-preparation\", \"self-criticism\"],\n",
    "    rigidity=0.8,\n",
    ")\n",
    "\n",
    "procrastinator = Firefighter(\n",
    "    narrative=\"The Procrastinator — shuts everything down when the pressure gets too high\",\n",
    "    age=14,\n",
    "    intent=\"Protect from overwhelm by stopping all effort\",\n",
    "    pain_threshold=0.6,\n",
    "    extinguishing_behaviors=[\"avoidance\", \"distraction\", \"numbing with screens\"],\n",
    ")\n",
    "\n",
    "wounded_child = Exile(\n",
    "    narrative=\"The Wounded Child — carries shame from being humiliated at school\",\n",
    "    age=7,\n",
    "    intent=\"Hold the pain so the system can function\",\n",
    "    emotional_charge=0.8,\n",
    "    burden=Burden(\n",
    "        burden_type=BurdenType.PERSONAL,\n",
    "        origin=\"Age 7, humiliated in front of the class\",\n",
    "        content=\"I am not good enough\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Add to session and wire relationships\n",
    "session.add_part(critic)\n",
    "session.add_part(procrastinator)\n",
    "session.add_part(wounded_child)\n",
    "\n",
    "session.add_edge(Edge(\n",
    "    source_id=critic.id,\n",
    "    target_id=wounded_child.id,\n",
    "    edge_type=EdgeType.PROTECTS,\n",
    "))\n",
    "session.add_edge(Edge(\n",
    "    source_id=procrastinator.id,\n",
    "    target_id=wounded_child.id,\n",
    "    edge_type=EdgeType.PROTECTS,\n",
    "))\n",
    "\n",
    "print(f\"Internal system: {len(session.graph.nodes)} Parts, {len(session.graph.edges)} edges\")\n",
    "print(f\"Self-energy: {session.self_system.self_energy}\")\n",
    "print(f\"Self-led: {session.is_self_led}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a7b8c9",
   "metadata": {},
   "source": [
    "## 2. Inspect the System Prompt\n",
    "\n",
    "Before we talk to a Part, let's see what the LLM actually receives. The system prompt is built from the Part's IFS data — narrative, age, intent, strategies, trust level. This is what grounds the LLM response in the Part's character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b8c9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System prompt for the Inner Critic\n",
    "prompt = build_part_system_prompt(critic)\n",
    "print(\"=== Inner Critic System Prompt ===\")\n",
    "print(prompt)\n",
    "print()\n",
    "\n",
    "# System prompt for the Wounded Child\n",
    "prompt_exile = build_part_system_prompt(wounded_child)\n",
    "print(\"=== Wounded Child System Prompt ===\")\n",
    "print(prompt_exile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c9d0e1",
   "metadata": {},
   "source": [
    "## 3. speak_as — Self Speaks to a Part\n",
    "\n",
    "In IFS, the facilitator (Self) approaches a Part with curiosity and compassion. `speak_as()` checks that Self-energy is above the compassion threshold before engaging — if another Part has blended, the system cannot hold the space.\n",
    "\n",
    "Let's ask the Inner Critic what its job is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d0e1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self speaks to the Inner Critic\n",
    "response = session.speak_as(\n",
    "    critic.id,\n",
    "    \"I notice you're very active right now. Can you tell me about your job in this system?\",\n",
    ")\n",
    "\n",
    "print(\"Inner Critic responds:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e1f2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Follow-up: ask what it's afraid would happen if it stopped\n",
    "response2 = session.speak_as(\n",
    "    critic.id,\n",
    "    \"I appreciate what you do for us. What are you afraid would happen if you stopped criticising?\",\n",
    ")\n",
    "\n",
    "print(\"Inner Critic responds:\")\n",
    "print(response2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f2a3b4",
   "metadata": {},
   "source": [
    "## 4. Multi-Turn Memory\n",
    "\n",
    "Each Part maintains its own conversation history. Subsequent calls to `speak_as()` carry the full history, so the Part remembers what was said and responds in context — just like a real therapeutic conversation builds over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a3b4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third turn — the Part has memory of the previous two exchanges\n",
    "response3 = session.speak_as(\n",
    "    critic.id,\n",
    "    \"Who is it that you're trying to protect?\",\n",
    ")\n",
    "\n",
    "print(\"Inner Critic responds:\")\n",
    "print(response3)\n",
    "\n",
    "# Show the conversation history\n",
    "print(\"\\n--- Conversation history ---\")\n",
    "history = session.dialogue.get_history(critic.id)\n",
    "for msg in history:\n",
    "    label = \"Self\" if msg.role == \"facilitator\" else \"Inner Critic\"\n",
    "    print(f\"\\n[{label}]: {msg.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b4c5d6",
   "metadata": {},
   "source": [
    "## 5. Direct Access — Therapist Bypasses Self\n",
    "\n",
    "In IFS, **Direct Access** is a technique where a skilled therapist speaks directly to a Part, bypassing the client's Self. This is used when:\n",
    "- Self-energy is too low for the client to engage\n",
    "- A Protector is too blended to step back\n",
    "- The therapist needs to negotiate directly with a protective Part\n",
    "\n",
    "In `agentic-ifs`, `direct_access()` skips the Self-energy check and adds a special instruction to the system prompt indicating a therapist is speaking directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c5d6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direct Access to the Procrastinator\n",
    "response_da = session.direct_access(\n",
    "    procrastinator.id,\n",
    "    \"Hi there. I'd like to speak with you directly. \"\n",
    "    \"I understand you step in when things get too much. \"\n",
    "    \"Can you tell me what you experience right before you take over?\",\n",
    ")\n",
    "\n",
    "print(\"Procrastinator (Direct Access):\")\n",
    "print(response_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d6e7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the Direct Access system prompt to see the difference\n",
    "prompt_da = build_part_system_prompt(procrastinator, is_direct_access=True)\n",
    "print(\"=== Direct Access System Prompt ===\")\n",
    "print(prompt_da)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e7f8a9",
   "metadata": {},
   "source": [
    "## 6. Speaking to the Exile\n",
    "\n",
    "The most delicate work in IFS is speaking with Exiles. The Wounded Child carries the burden — the belief \"I am not good enough\" — and speaks from age 7. The system prompt captures this developmental age, emotional charge, and burden content.\n",
    "\n",
    "In real therapy, this requires high Self-energy — you need to hold space with compassion. The library enforces this gate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f8a9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self speaks to the Wounded Child\n",
    "response_exile = session.speak_as(\n",
    "    wounded_child.id,\n",
    "    \"Hello little one. I'm here with you now. Can you tell me what happened?\",\n",
    ")\n",
    "\n",
    "print(\"Wounded Child responds:\")\n",
    "print(response_exile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a9b0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Follow-up with the Exile\n",
    "response_exile2 = session.speak_as(\n",
    "    wounded_child.id,\n",
    "    \"I'm so sorry that happened to you. What do you need from me right now?\",\n",
    ")\n",
    "\n",
    "print(\"Wounded Child responds:\")\n",
    "print(response_exile2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b0c1d2",
   "metadata": {},
   "source": [
    "## 7. Session Log\n",
    "\n",
    "Every dialogue exchange is logged in the `SelfSystem`'s session log. This provides a full audit trail of the therapeutic process — which Parts were engaged, what was said, and whether it was through Self or via Direct Access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c1d2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review the session log\n",
    "print(f\"Session log entries: {len(session.self_system.session_log)}\")\n",
    "print()\n",
    "for entry in session.self_system.session_log:\n",
    "    print(f\"[{entry.event_type}] {entry.timestamp.strftime('%H:%M:%S')}\")\n",
    "    # Truncate long descriptions for readability\n",
    "    desc = entry.description\n",
    "    if len(desc) > 120:\n",
    "        desc = desc[:120] + \"...\"\n",
    "    print(f\"  {desc}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d2e3f4",
   "metadata": {},
   "source": [
    "## 8. Using a Different Provider\n",
    "\n",
    "The dialogue system is **provider-agnostic**. The `DialogueProvider` protocol is a simple interface — any object with a `generate_part_response()` method works. You can use:\n",
    "\n",
    "- `GeminiDialogueProvider` — Google Gemini (this notebook)\n",
    "- `AnthropicDialogueProvider` — Anthropic Claude (`pip install agentic-ifs[anthropic]`)\n",
    "- **Your own provider** — implement the protocol for any LLM, local model, or rule-based system\n",
    "\n",
    "Here's a minimal mock provider to show the interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e3f4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agentic_ifs import DialogueProvider, DialogueContext, PartDialogue\n",
    "from agentic_ifs.parts import IPart\n",
    "\n",
    "\n",
    "class EchoProvider:\n",
    "    \"\"\"A mock provider that echoes the Part's intent.\n",
    "    \n",
    "    Shows how simple the DialogueProvider interface is — just\n",
    "    implement generate_part_response().\n",
    "    \"\"\"\n",
    "    def generate_part_response(\n",
    "        self, part: IPart, context: DialogueContext, system_prompt: str,\n",
    "    ) -> str:\n",
    "        return (\n",
    "            f\"[{part.part_type.title()} Part, age {part.age}] \"\n",
    "            f\"My job is to {part.intent.lower()}. \"\n",
    "            f\"You said: '{context.facilitator_message}'\"\n",
    "        )\n",
    "\n",
    "\n",
    "# Use the echo provider\n",
    "echo_session = Session(\n",
    "    initial_self_energy=0.8,\n",
    "    dialogue_provider=EchoProvider(),\n",
    ")\n",
    "echo_session.add_part(critic)\n",
    "\n",
    "echo_response = echo_session.speak_as(critic.id, \"How are you feeling?\")\n",
    "print(echo_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f4a5b6",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The LLM Part Dialogue system bridges the computational IFS model and natural language:\n",
    "\n",
    "| Feature | Method | Description |\n",
    "|---|---|---|\n",
    "| **Speak as Part** | `session.speak_as(part_id, message)` | Self speaks to a Part; requires Self-energy above compassion threshold |\n",
    "| **Direct Access** | `session.direct_access(part_id, message)` | Therapist speaks directly to a Part, bypassing Self |\n",
    "| **System prompts** | `build_part_system_prompt(part)` | IFS-grounded prompts from Part data (narrative, age, intent, strategies) |\n",
    "| **Conversation memory** | `session.dialogue.get_history(part_id)` | Multi-turn dialogue with per-Part history |\n",
    "| **Session logging** | `session.self_system.session_log` | Full audit trail of all dialogue exchanges |\n",
    "| **Provider agnostic** | `DialogueProvider` protocol | Plug in any LLM backend — Gemini, Claude, local models, or your own |\n",
    "\n",
    "The key insight: **the LLM is a rendering engine, not the IFS model.** The Part's character is encoded in its data fields. The LLM gives it a voice.\n",
    "\n",
    "**Next:** Try [07_unburdening.ipynb](07_unburdening.ipynb) to see the full therapeutic arc — from Protector dialogue through the unburdening pipeline."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}